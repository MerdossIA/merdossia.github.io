{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Introduction \u00e0 l'Intelligence Artificielle","text":"<p>L'intelligence artificielle (IA) est un domaine de l'informatique qui se concentre sur la cr\u00e9ation de syst\u00e8mes capables d'effectuer des t\u00e2ches qui n\u00e9cessitent g\u00e9n\u00e9ralement l'intelligence humaine. Ces t\u00e2ches incluent l'apprentissage, le raisonnement, la r\u00e9solution de probl\u00e8mes, la perception et la compr\u00e9hension du langage naturel.</p>"},{"location":"#developpement-de-lia","title":"D\u00e9veloppement de l'IA","text":"<p>L'IA a \u00e9volu\u00e9 depuis ses d\u00e9buts dans les ann\u00e9es 1950. Avec l'augmentation de la puissance de calcul, la disponibilit\u00e9 de grandes quantit\u00e9s de donn\u00e9es (Big Data), et les progr\u00e8s des algorithmes, l'IA a connu des avanc\u00e9es significatives dans des domaines tels que la reconnaissance d'images, le traitement du langage naturel, et les syst\u00e8mes de recommandation.</p>"},{"location":"#outils-interessants","title":"Outils Int\u00e9ressants","text":"<ul> <li>TensorFlow : Une biblioth\u00e8que open-source pour l'apprentissage automatique.</li> <li>PyTorch : Une autre biblioth\u00e8que populaire pour l'apprentissage automatique, particuli\u00e8rement utilis\u00e9e pour la recherche en deep learning.</li> <li>Scikit-Learn : Une biblioth\u00e8que pour l'apprentissage automatique en Python qui inclut de nombreux algorithmes de machine learning.</li> <li>Keras : Une interface haut niveau pour TensorFlow.</li> <li>OpenCV : Une biblioth\u00e8que de vision par ordinateur.</li> <li>NLTK : Un ensemble de biblioth\u00e8ques pour le traitement du langage naturel.</li> </ul>"},{"location":"#modeles-existant","title":"Mod\u00e8les Existant","text":"<ul> <li>R\u00e9seaux de Neurones Convolutifs (CNN) : Utilis\u00e9s principalement pour la reconnaissance d'images.</li> <li>R\u00e9seaux de Neurones R\u00e9currents (RNN) : Utilis\u00e9s pour les donn\u00e9es s\u00e9quentielles telles que le texte et les s\u00e9ries temporelles.</li> <li>Transformers : Utilis\u00e9s pour le traitement du langage naturel (par exemple, BERT, GPT).</li> <li>GANs (Generative Adversarial Networks) : Utilis\u00e9s pour g\u00e9n\u00e9rer des donn\u00e9es nouvelles et r\u00e9alistes.</li> <li>Auto-encoders : Utilis\u00e9s pour la r\u00e9duction de dimensions et la d\u00e9tection d'anomalies.</li> </ul>"},{"location":"#derniers-ecrits-litterature","title":"Derniers \u00c9crits Litt\u00e9rature","text":"<p>Pour rester \u00e0 jour avec les derni\u00e8res avanc\u00e9es en IA, il est recommand\u00e9 de suivre des conf\u00e9rences telles que NeurIPS, ICML, CVPR, et de lire des articles sur des plateformes comme arXiv, IEEE Xplore, et les journaux sp\u00e9cifiques \u00e0 l'IA.</p>"},{"location":"definitions/","title":"D\u00e9finitions des Mots Cl\u00e9s","text":"<ul> <li>Machine Learning (Apprentissage Automatique) : Sous-domaine de l'IA qui se concentre sur le d\u00e9veloppement d'algorithmes permettant aux ordinateurs d'apprendre \u00e0 partir de donn\u00e9es.</li> <li>Deep Learning (Apprentissage Profond) : Sous-ensemble du machine learning qui utilise des r\u00e9seaux de neurones artificiels avec de nombreuses couches.</li> <li>Supervised Learning (Apprentissage Supervis\u00e9) : Technique o\u00f9 le mod\u00e8le est entra\u00een\u00e9 sur des donn\u00e9es d'entr\u00e9e et des sorties correspondantes.</li> <li>Unsupervised Learning (Apprentissage Non Supervis\u00e9) : Technique o\u00f9 le mod\u00e8le est entra\u00een\u00e9 sur des donn\u00e9es sans \u00e9tiquettes de sortie.</li> <li>Reinforcement Learning (Apprentissage par Renforcement) : Technique o\u00f9 un agent apprend \u00e0 interagir avec son environnement pour maximiser une r\u00e9compense cumul\u00e9e.</li> <li>Neural Network (R\u00e9seau de Neurones) : Mod\u00e8le informatique inspir\u00e9 du cerveau humain, utilis\u00e9 dans le deep learning.</li> <li>Overfitting (Surapprentissage) : Situation o\u00f9 un mod\u00e8le apprend trop bien les d\u00e9tails et le bruit des donn\u00e9es d'entra\u00eenement, affectant ainsi sa performance sur les nouvelles donn\u00e9es.</li> <li>Cross-validation (Validation Crois\u00e9e) : Technique utilis\u00e9e pour \u00e9valuer la performance d'un mod\u00e8le en le testant sur diff\u00e9rentes partitions des donn\u00e9es.</li> </ul>"},{"location":"examples/","title":"Exemples d'Utilisation","text":""},{"location":"examples/#chargement-de-la-configuration","title":"Chargement de la Configuration","text":"<p>```python from project.H2.ia.config import Config</p> <p>config = Config(config_path='path/to/config.json')</p>"},{"location":"examples/#pretraitement-des-donnees","title":"Pr\u00e9traitement des Donn\u00e9es","text":"<p>```python from project.H2.ia.data.data_processor import DataProcessor</p> <p>data_processor = DataProcessor(config=config) data = data_processor.handle_missing_values(df=data)</p>"},{"location":"examples/#entrainement-dun-modele","title":"Entra\u00eenement d'un Mod\u00e8le","text":"<p>```python from project.H2.ia.model.model_trainer import ModelTrainer</p> <p>trainer = ModelTrainer(data=data, model_name='RandomForest', config=config) trainer.train(X_train, y_train, X_val, y_val)</p>"},{"location":"flowchart/","title":"Diagramme de Flux","text":"<p>Voici le diagramme de flux de notre projet :</p> <p></p>"},{"location":"latest_advancements/","title":"Derni\u00e8res Avanc\u00e9es en Entra\u00eenement de Mod\u00e8les IA","text":""},{"location":"latest_advancements/#techniques-innovantes","title":"Techniques Innovantes","text":"<ol> <li>Low Rank Adaptation (LoRA)</li> <li>Description : Technique de fine-tuning des mod\u00e8les en injectant des couches entra\u00eenables, r\u00e9duisant ainsi le nombre de param\u00e8tres \u00e0 mettre \u00e0 jour.</li> <li> <p>Avantages : Acc\u00e9l\u00e8re le fine-tuning et r\u00e9duit la m\u00e9moire n\u00e9cessaire pour stocker les mises \u00e0 jour du mod\u00e8le\u301051\u2020source\u3011.</p> </li> <li> <p>Quantization</p> </li> <li>Description : R\u00e9duction de la pr\u00e9cision utilis\u00e9e pour repr\u00e9senter les points de donn\u00e9es du mod\u00e8le (par exemple, de 16 bits \u00e0 8 bits).</li> <li> <p>Avantages : R\u00e9duit l'utilisation de la m\u00e9moire et acc\u00e9l\u00e8re l'inf\u00e9rence. Techniques comme QLoRA combinent quantization et LoRA\u301051\u2020source\u3011.</p> </li> <li> <p>Direct Preference Optimization (DPO)</p> </li> <li>Description : M\u00e9thode d'alignement des sorties des mod\u00e8les sur les pr\u00e9f\u00e9rences humaines, simplifiant les processus complexes de RLHF.</li> <li> <p>Avantages : L\u00e9ger en termes de calcul et stable\u301051\u2020source\u3011.</p> </li> <li> <p>Federated Learning</p> </li> <li>Description : Entra\u00eenement de mod\u00e8les sur plusieurs dispositifs sans partager les donn\u00e9es brutes.</li> <li> <p>Avantages : Am\u00e9liore la confidentialit\u00e9 et la s\u00e9curit\u00e9, particuli\u00e8rement utile dans les domaines sensibles comme la sant\u00e9\u301042\u2020source\u3011.</p> </li> <li> <p>Meta-Learning</p> </li> <li>Description : Apprentissage sur l'apprentissage, permettant aux mod\u00e8les de s'adapter rapidement \u00e0 de nouvelles t\u00e2ches avec peu de donn\u00e9es d'entra\u00eenement.</li> <li> <p>Avantages : Am\u00e9liore l'efficacit\u00e9 de l'apprentissage dans divers contextes\u301042\u2020source\u3011.</p> </li> <li> <p>Optimisation par Algorithmes G\u00e9n\u00e9tiques</p> </li> <li>Description : Exploration de l'espace des hyperparam\u00e8tres de mani\u00e8re efficace en utilisant des techniques inspir\u00e9es de l'\u00e9volution.</li> <li> <p>Avantages : Am\u00e9liore les performances des mod\u00e8les complexes\u301043\u2020source\u3011.</p> </li> <li> <p>Graph Neural Networks (GNN)</p> </li> <li>Description : Utilisation pour des donn\u00e9es structur\u00e9es en graphes, comme les r\u00e9seaux sociaux ou les mol\u00e9cules en chimie computationnelle.</li> <li> <p>Avantages : Nouvelles applications dans des domaines complexes comme la chimie computationnelle et les r\u00e9seaux sociaux\u301042\u2020source\u3011.</p> </li> <li> <p>Edge Computing pour le D\u00e9ploiement de l'IA</p> </li> <li>Description : D\u00e9ploiement de mod\u00e8les IA pr\u00e8s de la source des donn\u00e9es, r\u00e9duisant la latence et am\u00e9liorant les temps de r\u00e9ponse.</li> <li>Avantages : Utilisation croissante dans des applications en temps r\u00e9el et des environnements o\u00f9 la bande passante est limit\u00e9e\u301043\u2020source\u3011.</li> </ol>"},{"location":"latest_advancements/#exemples-recents-de-modeles-de-training","title":"Exemples R\u00e9cents de Mod\u00e8les de Training","text":"<ol> <li>YOLOv9</li> <li>Description : Mod\u00e8le de d\u00e9tection d'objets en temps r\u00e9el am\u00e9lior\u00e9.</li> <li> <p>Avantages : Meilleure performance par rapport aux versions pr\u00e9c\u00e9dentes avec des techniques comme Programmable Gradient Information (PGI) et GELAN\u301057\u2020source\u3011.</p> </li> <li> <p>GPT-4</p> </li> <li>Description : Mod\u00e8le de langage multimodal capable de traiter des entr\u00e9es texte et image.</li> <li> <p>Avantages : Utilis\u00e9 pour des t\u00e2ches complexes comme la g\u00e9n\u00e9ration de texte, la compr\u00e9hension de contextes multiples et l'am\u00e9lioration des capacit\u00e9s de conversation\u301055\u2020source\u3011.</p> </li> <li> <p>StableRep</p> </li> <li>Description : Utilisation d'images synth\u00e9tiques pour l'entra\u00eenement des mod\u00e8les de reconnaissance visuelle.</li> <li> <p>Avantages : Performances am\u00e9lior\u00e9es par rapport aux donn\u00e9es r\u00e9elles, montrant le potentiel des donn\u00e9es synth\u00e9tiques pour l'apprentissage contrastif\u301056\u2020source\u3011.</p> </li> <li> <p>VILA</p> </li> <li>Description : Mod\u00e8les de vision-langage d\u00e9velopp\u00e9s par NVIDIA et MIT.</li> <li>Avantages : Compr\u00e9hension avanc\u00e9e des images, vid\u00e9os et textes, applicable \u00e0 des domaines comme les v\u00e9hicules autonomes et l'\u00e9dition de contenu visuel\u301058\u2020source\u3011.</li> </ol>"},{"location":"model_improvements/","title":"Am\u00e9liorations de Mod\u00e8les","text":""},{"location":"model_improvements/#introduction","title":"Introduction","text":"<p>Dans cette section, nous d\u00e9taillons toutes les \u00e9tapes d'am\u00e9lioration de l'entra\u00eenement des mod\u00e8les, y compris les derni\u00e8res m\u00e9thodes de pointe et ce qui n'existe pas encore mais pourrait \u00eatre envisag\u00e9.</p>"},{"location":"model_improvements/#etapes-actuelles","title":"\u00c9tapes Actuelles","text":"<ol> <li>Pr\u00e9-traitement des Donn\u00e9es</li> <li>Gestion des valeurs manquantes</li> <li>Encodage des variables cat\u00e9gorielles</li> <li> <p>Normalisation des donn\u00e9es</p> </li> <li> <p>Ing\u00e9nierie des Caract\u00e9ristiques</p> </li> <li>Cr\u00e9ation de nouvelles caract\u00e9ristiques \u00e0 partir des donn\u00e9es existantes</li> <li> <p>S\u00e9lection des caract\u00e9ristiques importantes</p> </li> <li> <p>Augmentation des Donn\u00e9es</p> </li> <li>Techniques de sur\u00e9chantillonnage et de sous-\u00e9chantillonnage</li> <li>Ajout de bruit gaussien</li> <li> <p>Transformations diverses</p> </li> <li> <p>Entra\u00eenement et Optimisation des Mod\u00e8les</p> </li> <li>Choix des algorithmes</li> <li>Optimisation des hyperparam\u00e8tres</li> <li>Validation crois\u00e9e</li> </ol>"},{"location":"model_improvements/#methodes-de-pointe","title":"M\u00e9thodes de Pointe","text":"<ul> <li>Ensemble Learning</li> <li>Random Forests</li> <li> <p>Gradient Boosting</p> </li> <li> <p>Apprentissage Profond</p> </li> <li>R\u00e9seaux de neurones convolutionnels</li> <li> <p>R\u00e9seaux de neurones r\u00e9currents</p> </li> <li> <p>Optimisation Bay\u00e9sienne</p> </li> <li>Utilisation pour l'ajustement des hyperparam\u00e8tres</li> </ul>"},{"location":"model_improvements/#methodes-futuristes","title":"M\u00e9thodes Futuristes","text":"<ol> <li>Optimisation par Algorithmes G\u00e9n\u00e9tiques</li> <li> <p>Exploration des hyperparam\u00e8tres \u00e0 l'aide de techniques inspir\u00e9es de l'\u00e9volution</p> </li> <li> <p>Int\u00e9gration de Meta-Learning</p> </li> <li> <p>Apprentissage sur l'apprentissage pour am\u00e9liorer la performance des mod\u00e8les</p> </li> <li> <p>Utilisation de Graph Neural Networks</p> </li> <li>Applications dans des domaines complexes tels que la chimie computationnelle et les r\u00e9seaux sociaux</li> </ol>"},{"location":"structure/","title":"Structure du Projet","text":"<p>Pour faciliter la compr\u00e9hension et l'utilisation de votre projet Python, je vais cr\u00e9er une documentation d\u00e9taill\u00e9e d\u00e9crivant chaque fichier, classe, attribut, et fonction mentionn\u00e9s. Cette documentation vous permettra d'avoir une vue d'ensemble claire de votre projet et de ses composants.</p>"},{"location":"structure/#fichiers-et-classes","title":"Fichiers et Classes","text":""},{"location":"structure/#projecth2iaconfigpy","title":"<code>project/H2.ia/config.py</code>","text":""},{"location":"structure/#classe-config","title":"Classe: <code>Config</code>","text":"<ul> <li>Attributs:<ul> <li><code>config_path</code>: Chemin vers le fichier de configuration.</li> <li><code>config</code>: Dictionnaire contenant la configuration charg\u00e9e.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, config_path)</code>: Initialise l'objet Config avec le chemin du fichier de configuration.</li> <li><code>get(self, section, key)</code>: Retourne la valeur associ\u00e9e \u00e0 la section et \u00e0 la cl\u00e9.</li> <li><code>set(self, section, key, value)</code>: D\u00e9finit la valeur pour une section et une cl\u00e9 donn\u00e9es.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iaanalysisdata_visualizationpy","title":"<code>project/H2.ia/analysis/data_visualization.py</code>","text":""},{"location":"structure/#classe-datavisualization","title":"Classe: <code>DataVisualization</code>","text":"<ul> <li>Attributs:<ul> <li><code>config</code>: Configuration pour la visualisation des donn\u00e9es.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, config)</code>: Initialise l'objet DataVisualization avec la configuration donn\u00e9e.</li> <li><code>plot_histogram(self, df)</code>: G\u00e9n\u00e8re un histogramme \u00e0 partir du DataFrame donn\u00e9.</li> <li><code>plot_correlation_matrix(self, df)</code>: G\u00e9n\u00e8re une matrice de corr\u00e9lation \u00e0 partir du DataFrame donn\u00e9.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iaanalysisstatistics_generatorpy","title":"<code>project/H2.ia/analysis/statistics_generator.py</code>","text":""},{"location":"structure/#classe-statisticsgenerator","title":"Classe: <code>StatisticsGenerator</code>","text":"<ul> <li>Attributs:<ul> <li><code>config</code>: Configuration pour la g\u00e9n\u00e9ration de statistiques.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, config)</code>: Initialise l'objet StatisticsGenerator avec la configuration donn\u00e9e.</li> <li><code>generate_statistics(self, df)</code>: G\u00e9n\u00e8re des statistiques descriptives \u00e0 partir du DataFrame donn\u00e9.</li> <li><code>generate_correlation_matrix(self, df)</code>: G\u00e9n\u00e8re une matrice de corr\u00e9lation \u00e0 partir du DataFrame donn\u00e9.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iadatadata_augmentationpy","title":"<code>project/H2.ia/data/data_augmentation.py</code>","text":""},{"location":"structure/#classe-dataaugmentation","title":"Classe: <code>DataAugmentation</code>","text":"<ul> <li>Attributs:<ul> <li><code>data</code>: Donn\u00e9es \u00e0 augmenter.</li> <li><code>target</code>: Cible des donn\u00e9es.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, data, target)</code>: Initialise l'objet DataAugmentation avec les donn\u00e9es et la cible donn\u00e9es.</li> <li><code>bootstrap_resample(self, n_samples)</code>: Effectue un r\u00e9\u00e9chantillonnage bootstrap des donn\u00e9es.</li> <li><code>add_gaussian_noise(self, noise_level)</code>: Ajoute du bruit gaussien aux donn\u00e9es.</li> <li><code>augment_balanced(self, method)</code>: Augmente les donn\u00e9es en utilisant une m\u00e9thode d'\u00e9quilibrage.</li> <li><code>augment_with_transformations(self, transformations)</code>: Augmente les donn\u00e9es en utilisant des transformations sp\u00e9cifi\u00e9es.</li> <li><code>save_augmented_data(self, filepath, file_type)</code>: Sauvegarde les donn\u00e9es augment\u00e9es dans un fichier.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iadatadata_processorpy","title":"<code>project/H2.ia/data/data_processor.py</code>","text":""},{"location":"structure/#classe-dataprocessor","title":"Classe: <code>DataProcessor</code>","text":"<ul> <li>Attributs:<ul> <li><code>config</code>: Configuration pour le traitement des donn\u00e9es.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, config)</code>: Initialise l'objet DataProcessor avec la configuration donn\u00e9e.</li> <li><code>handle_missing_values(self, df)</code>: Traite les valeurs manquantes dans le DataFrame donn\u00e9.</li> <li><code>encode_categorical(self, df)</code>: Encode les variables cat\u00e9gorielles dans le DataFrame donn\u00e9.</li> <li><code>normalize_data(self, df)</code>: Normalise les donn\u00e9es dans le DataFrame donn\u00e9.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iafeaturesfeature_engineeringpy","title":"<code>project/H2.ia/features/feature_engineering.py</code>","text":""},{"location":"structure/#classe-featureengineering","title":"Classe: <code>FeatureEngineering</code>","text":"<ul> <li>Attributs:<ul> <li><code>config</code>: Configuration pour l'ing\u00e9nierie des caract\u00e9ristiques.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, config)</code>: Initialise l'objet FeatureEngineering avec la configuration donn\u00e9e.</li> <li><code>create_features(self, df)</code>: Cr\u00e9e de nouvelles caract\u00e9ristiques \u00e0 partir du DataFrame donn\u00e9.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iafeaturesfeature_selectionpy","title":"<code>project/H2.ia/features/feature_selection.py</code>","text":""},{"location":"structure/#classe-featureselection","title":"Classe: <code>FeatureSelection</code>","text":"<ul> <li>Attributs:<ul> <li><code>config</code>: Configuration pour la s\u00e9lection des caract\u00e9ristiques.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, config)</code>: Initialise l'objet FeatureSelection avec la configuration donn\u00e9e.</li> <li><code>select_features(self, X, y)</code>: S\u00e9lectionne les meilleures caract\u00e9ristiques \u00e0 partir des donn\u00e9es donn\u00e9es.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iamodelbase_modelpy","title":"<code>project/H2.ia/model/base_model.py</code>","text":""},{"location":"structure/#classe-basemodel","title":"Classe: <code>BaseModel</code>","text":"<ul> <li>Attributs:<ul> <li><code>model_name</code>: Nom du mod\u00e8le.</li> <li><code>model_params</code>: Param\u00e8tres du mod\u00e8le.</li> <li><code>model</code>: Instance du mod\u00e8le.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, model_name, model_params)</code>: Initialise l'objet BaseModel avec le nom et les param\u00e8tres du mod\u00e8le.</li> <li><code>train(self, X_train, y_train)</code>: Entra\u00eene le mod\u00e8le avec les donn\u00e9es d'entra\u00eenement fournies.</li> <li><code>predict(self, X_test)</code>: Pr\u00e9dit les r\u00e9sultats pour les donn\u00e9es de test fournies.</li> <li><code>evaluate(self, X_test, y_test)</code>: \u00c9value le mod\u00e8le avec les donn\u00e9es de test fournies.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iamodelhyperparameter_optimizationpy","title":"<code>project/H2.ia/model/hyperparameter_optimization.py</code>","text":""},{"location":"structure/#classe-hyperparameteroptimization","title":"Classe: <code>HyperparameterOptimization</code>","text":"<ul> <li>Attributs:<ul> <li><code>model</code>: Mod\u00e8le \u00e0 optimiser.</li> <li><code>param_grid</code>: Grille de param\u00e8tres pour l'optimisation.</li> <li><code>param_distributions</code>: Distributions de param\u00e8tres pour l'optimisation.</li> <li><code>search_method</code>: M\u00e9thode de recherche pour l'optimisation.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, model, param_grid, param_distributions, search_method)</code>: Initialise l'objet HyperparameterOptimization avec le mod\u00e8le et les param\u00e8tres donn\u00e9s.</li> <li><code>grid_search(self, X, y)</code>: Effectue une recherche en grille pour optimiser les hyperparam\u00e8tres.</li> <li><code>random_search(self, X, y)</code>: Effectue une recherche al\u00e9atoire pour optimiser les hyperparam\u00e8tres.</li> <li><code>optuna_search(self, objective, n_trials)</code>: Utilise Optuna pour optimiser les hyperparam\u00e8tres.</li> <li><code>hyperopt_search(self, objective, space, max_evals)</code>: Utilise Hyperopt pour optimiser les hyperparam\u00e8tres.</li> <li><code>bayesian_optimization(self, pbounds, init_points, n_iter)</code>: Utilise l'optimisation bay\u00e9sienne pour optimiser les hyperparam\u00e8tres.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iamodelmodel_trainerpy","title":"<code>project/H2.ia/model/model_trainer.py</code>","text":""},{"location":"structure/#classe-modeltrainer","title":"Classe: <code>ModelTrainer</code>","text":"<ul> <li>Attributs:<ul> <li><code>X_train</code>: Donn\u00e9es d'entra\u00eenement.</li> <li><code>results</code>: R\u00e9sultats de l'entra\u00eenement.</li> <li><code>model_name</code>: Nom du mod\u00e8le.</li> <li><code>config</code>: Configuration pour l'entra\u00eenement du mod\u00e8le.</li> <li><code>X_test</code>: Donn\u00e9es de test.</li> <li><code>model_params</code>: Param\u00e8tres du mod\u00e8le.</li> <li><code>train_params</code>: Param\u00e8tres d'entra\u00eenement.</li> <li><code>layers</code>: Couches du mod\u00e8le.</li> <li><code>y_test</code>: Cibles des donn\u00e9es de test.</li> <li><code>split_params</code>: Param\u00e8tres de division des donn\u00e9es.</li> <li><code>y_train</code>: Cibles des donn\u00e9es d'entra\u00eenement.</li> <li><code>model</code>: Instance du mod\u00e8le.</li> <li><code>data</code>: Donn\u00e9es \u00e0 utiliser pour l'entra\u00eenement.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, data, model_name, config)</code>: Initialise l'objet ModelTrainer avec les donn\u00e9es, le nom du mod\u00e8le et la configuration donn\u00e9s.</li> <li><code>build_tensorflow_model(self, input_shape, layers, dropout_rate)</code>: Construit un mod\u00e8le TensorFlow avec les param\u00e8tres donn\u00e9s.</li> <li><code>build_pytorch_model(self, input_dim, layers, dropout_rate)</code>: Construit un mod\u00e8le PyTorch avec les param\u00e8tres donn\u00e9s.</li> <li><code>train(self, X_train, y_train, X_val, y_val, epochs, batch_size)</code>: Entra\u00eene le mod\u00e8le avec les donn\u00e9es et param\u00e8tres d'entra\u00eenement donn\u00e9s.</li> <li><code>predict(self, X)</code>: Pr\u00e9dit les r\u00e9sultats pour les donn\u00e9es fournies.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2ianewsmodelensemble_learningpy","title":"<code>project/H2.ia/news/modelensemble_learning.py</code>","text":""},{"location":"structure/#classe-ensemblelearning","title":"Classe: <code>EnsembleLearning</code>","text":"<ul> <li>Attributs:<ul> <li><code>gradient_boosting</code>: Mod\u00e8le de boosting par gradient.</li> <li><code>stacking</code>: Mod\u00e8le de stacking.</li> <li><code>random_forest</code>: Mod\u00e8le de for\u00eat al\u00e9atoire.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>train(self, X, y)</code>: Entra\u00eene le mod\u00e8le d'ensemble avec les donn\u00e9es fournies.</li> <li><code>predict(self, X)</code>: Pr\u00e9dit les r\u00e9sultats pour les donn\u00e9es fournies.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2ianewsmodelregularizationpy","title":"<code>project/H2.ia/news/modelregularization.py</code>","text":""},{"location":"structure/#classe-regularization","title":"Classe: <code>Regularization</code>","text":"<ul> <li>Attributs:<ul> <li><code>method</code>: M\u00e9thode de r\u00e9gularisation.</li> <li><code>alpha</code>: Param\u00e8tre de r\u00e9gularisation.</li> </ul> </li> <li>M\u00e9thodes:<ul> <li><code>__init__(self, method, alpha)</code>: Initialise l'objet Regularization avec la m\u00e9thode et le param\u00e8tre alpha donn\u00e9s.</li> <li><code>train(self, X, y)</code>: Entra\u00eene le mod\u00e8le avec r\u00e9gularisation sur les donn\u00e9es fournies.</li> <li><code>predict(self, X)</code>: Pr\u00e9dit les r\u00e9sultats pour les donn\u00e9es fournies.</li> </ul> </li> </ul>"},{"location":"structure/#projecth2iautilsloggerpy","title":"<code>project/H2.ia/utils/logger.py</code>","text":""},{"location":"structure/#methodes","title":"M\u00e9thodes:","text":"<pre><code>- `setup_logger(name, log_file, level)`: Configure le logger avec le nom, le fichier de log et le niveau donn\u00e9s.\n</code></pre>"},{"location":"structure/#fichier-de-configuration-json","title":"Fichier de Configuration JSON","text":""},{"location":"structure/#projecth2iaconfigjson","title":"<code>project/H2.ia/config.json</code>","text":"<p>```json {   \"data_loader\": {     \"file_type\": \"csv\",     \"sep\": \",\",     \"encoding\": \"utf-8\",     \"sheet_name\": 0,     \"columns\": null,     \"index_col\": null,     \"sql_query\": null,     \"xml_path\": null,     \"db_uri\": null,     \"filepath\": \"path/to/data.csv\"   },   \"remove_duplicates\": {     \"method\": \"drop\",     \"subset\": null,     \"mark_column\": \"is_duplicate\"   },   \"handle_missing_values\": {     \"method\": \"fill_mean\",     \"value\": null,     \"subset\": null,     \"custom_func\": null,     \"n_neighbors\": 5   },   ... }</p>"},{"location":"tools_not_included/","title":"Outils Non Inclus dans le Projet","text":"<p>Voici quelques outils et mod\u00e8les existants qui ne sont pas encore \u00e9tudi\u00e9s dans le projet :</p> <ul> <li>XGBoost : Impl\u00e9mentation optimis\u00e9e de l'algorithme de boosting des arbres de d\u00e9cision.</li> <li>LightGBM : Un autre framework de boosting, optimis\u00e9 pour la vitesse et les performances.</li> <li>CatBoost : Framework de boosting d\u00e9velopp\u00e9 par Yandex, performant avec les donn\u00e9es cat\u00e9gorielles.</li> <li>Reinforcement Learning Frameworks : TensorFlow Agents, OpenAI Gym.</li> <li>NLP Models : GPT-3, T5, BART.</li> <li>Computer Vision Models : EfficientNet, YOLO, DETR.</li> </ul> <p>Ces outils peuvent \u00eatre explor\u00e9s pour des am\u00e9liorations futures du projet en fonction des besoins sp\u00e9cifiques de votre application.</p>"}]}